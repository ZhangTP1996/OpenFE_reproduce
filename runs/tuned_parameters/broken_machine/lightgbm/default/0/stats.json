{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/broken_machine"
        },
        "fit": {
            "early_stopping_rounds": 1999,
            "verbose": true
        },
        "model": {
            "n_estimators": 2000
        },
        "seed": 0
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "455.32.00",
            "0": {
                "name": "Tesla V100-PCIE-16GB",
                "total_memory": 16945512448
            }
        }
    },
    "dataset": "broken_machine",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7800574895432641,
                "recall": 0.9765652781464582,
                "f1-score": 0.867320033939809,
                "support": 399322
            },
            "1": {
                "precision": 0.8770027469999868,
                "recall": 0.3776644517144183,
                "f1-score": 0.527969109158454,
                "support": 176678
            },
            "accuracy": 0.7928628472222222,
            "macro avg": {
                "precision": 0.8285301182716255,
                "recall": 0.6771148649304383,
                "f1-score": 0.6976445715491315,
                "support": 576000
            },
            "weighted avg": {
                "precision": 0.8097937641907275,
                "recall": 0.7928628472222222,
                "f1-score": 0.7632300292722392,
                "support": 576000
            },
            "roc_auc": 0.8910530093349124,
            "score": 0.7928628472222222
        },
        "val": {
            "0": {
                "precision": 0.7529784607157742,
                "recall": 0.9591405389161575,
                "f1-score": 0.8436471609256674,
                "support": 99830
            },
            "1": {
                "precision": 0.7577359387064204,
                "recall": 0.2888385782205117,
                "f1-score": 0.41824708639992136,
                "support": 44170
            },
            "accuracy": 0.7535347222222222,
            "macro avg": {
                "precision": 0.7553571997110973,
                "recall": 0.6239895585683346,
                "f1-score": 0.6309471236627944,
                "support": 144000
            },
            "weighted avg": {
                "precision": 0.7544377510133218,
                "recall": 0.7535347222222222,
                "f1-score": 0.7131615963992632,
                "support": 144000
            },
            "roc_auc": 0.7486221845418852,
            "score": 0.7535347222222222
        },
        "test": {
            "0": {
                "precision": 0.7543051573674427,
                "recall": 0.9593230118280603,
                "f1-score": 0.844549953614375,
                "support": 124788
            },
            "1": {
                "precision": 0.7616341864287391,
                "recall": 0.29375860320220243,
                "f1-score": 0.4239873475629681,
                "support": 55212
            },
            "accuracy": 0.7551722222222222,
            "macro avg": {
                "precision": 0.757969671898091,
                "recall": 0.6265408075151314,
                "f1-score": 0.6342686505886715,
                "support": 180000
            },
            "weighted avg": {
                "precision": 0.7565532148815111,
                "recall": 0.7551722222222222,
                "f1-score": 0.7155493835848734,
                "support": 180000
            },
            "roc_auc": 0.7473083614462741,
            "score": 0.7551722222222222
        }
    },
    "time": "0:03:59"
}
