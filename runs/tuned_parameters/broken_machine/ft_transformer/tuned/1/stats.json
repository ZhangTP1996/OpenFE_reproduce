{
    "dataset": "broken_machine",
    "algorithm": "ft_transformer",
    "config": {
        "data": {
            "cat_policy": "indices",
            "normalization": "quantile",
            "path": "data/broken_machine"
        },
        "model": {
            "activation": "reglu",
            "attention_dropout": 0.4178066644252025,
            "d_ffn_factor": 1.333333333333333,
            "d_token": 432,
            "ffn_dropout": 0.06337002372307488,
            "initialization": "kaiming",
            "n_heads": 8,
            "n_layers": 3,
            "prenormalization": true,
            "residual_dropout": 0.0
        },
        "seed": 1,
        "training": {
            "batch_size": 1024,
            "eval_batch_size": 8192,
            "lr": 7.523375809438358e-05,
            "n_epochs": 1000000000,
            "optimizer": "adamw",
            "patience": 16,
            "weight_decay": 0.0002871929965055266
        }
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "1,2,3",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "455.32.00",
            "1": {
                "name": "Tesla V100-PCIE-16GB",
                "total_memory": 16945512448
            },
            "2": {
                "name": "Tesla V100-PCIE-16GB",
                "total_memory": 16945512448
            },
            "3": {
                "name": "Tesla V100-PCIE-16GB",
                "total_memory": 16945512448
            }
        }
    },
    "epoch_size": 563,
    "n_parameters": 4541179,
    "best_epoch": 126,
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7942834572156989,
                "recall": 0.9416961750166533,
                "f1-score": 0.8617309554227703,
                "support": 399322
            },
            "1": {
                "precision": 0.7730069125547203,
                "recall": 0.4487542308606618,
                "f1-score": 0.5678526025533134,
                "support": 176678
            },
            "accuracy": 0.7904947916666667,
            "macro avg": {
                "precision": 0.7836451848852096,
                "recall": 0.6952252029386575,
                "f1-score": 0.7147917789880418,
                "support": 576000
            },
            "weighted avg": {
                "precision": 0.7877572465253997,
                "recall": 0.7904947916666667,
                "f1-score": 0.7715888727348017,
                "support": 576000
            },
            "roc_auc": 0.8132260763331082,
            "score": 0.8132260763331082
        },
        "val": {
            "0": {
                "precision": 0.7920166467886416,
                "recall": 0.9379244716017229,
                "f1-score": 0.8588174326189745,
                "support": 99830
            },
            "1": {
                "precision": 0.7596105357073587,
                "recall": 0.44333257867330766,
                "f1-score": 0.5598936367925202,
                "support": 44170
            },
            "accuracy": 0.7862152777777778,
            "macro avg": {
                "precision": 0.7758135912480002,
                "recall": 0.6906285251375153,
                "f1-score": 0.7093555347057474,
                "support": 144000
            },
            "weighted avg": {
                "precision": 0.7820765222993343,
                "recall": 0.7862152777777778,
                "f1-score": 0.7671267099685961,
                "support": 144000
            },
            "roc_auc": 0.8059099729218185,
            "score": 0.8059099729218185
        },
        "test": {
            "0": {
                "precision": 0.7918765913646459,
                "recall": 0.9370933102541911,
                "f1-score": 0.8583865521544446,
                "support": 124788
            },
            "1": {
                "precision": 0.7571764414748825,
                "recall": 0.44334564949648625,
                "f1-score": 0.5592414896047522,
                "support": 55212
            },
            "accuracy": 0.7856444444444445,
            "macro avg": {
                "precision": 0.7745265164197642,
                "recall": 0.6902194798753387,
                "f1-score": 0.7088140208795983,
                "support": 180000
            },
            "weighted avg": {
                "precision": 0.7812328987217926,
                "recall": 0.7856444444444445,
                "f1-score": 0.7666287899683689,
                "support": 180000
            },
            "roc_auc": 0.8069591372907741,
            "score": 0.8069591372907741
        }
    },
    "time": "1:59:48"
}
