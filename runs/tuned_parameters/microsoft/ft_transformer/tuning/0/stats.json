{
    "config": {
        "base_config": {
            "data": {
                "normalization": "quantile",
                "path": "data/microsoft",
                "y_policy": "mean_std"
            },
            "model": {
                "activation": "reglu",
                "d_ffn_factor": 1.333333333333333,
                "initialization": "kaiming",
                "n_heads": 8,
                "prenormalization": true,
                "residual_dropout": 0.0
            },
            "seed": 0,
            "training": {
                "batch_size": 1024,
                "eval_batch_size": 8192,
                "n_epochs": 1000000000,
                "optimizer": "adamw",
                "patience": 16
            }
        },
        "optimization": {
            "options": {
                "n_trials": 50
            },
            "sampler": {
                "seed": 0
            },
            "space": {
                "model": {
                    "attention_dropout": [
                        "uniform",
                        0.0,
                        0.5
                    ],
                    "d_token": [
                        "$d_token",
                        64,
                        512
                    ],
                    "ffn_dropout": [
                        "uniform",
                        0.0,
                        0.5
                    ],
                    "n_layers": [
                        "int",
                        1,
                        6
                    ]
                },
                "training": {
                    "lr": [
                        "loguniform",
                        3e-05,
                        0.0003
                    ],
                    "weight_decay": [
                        "loguniform",
                        1e-06,
                        0.001
                    ]
                }
            }
        },
        "program": "bin/ft_transformer.py"
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0,1,2",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            },
            "1": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            },
            "2": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "continuations": [
        15
    ],
    "best_stats": {
        "dataset": "microsoft",
        "algorithm": "ft_transformer",
        "config": {
            "data": {
                "normalization": "quantile",
                "path": "data/microsoft",
                "y_policy": "mean_std"
            },
            "model": {
                "activation": "reglu",
                "attention_dropout": 0.2367026970034473,
                "d_ffn_factor": 1.333333333333333,
                "d_token": 104,
                "ffn_dropout": 0.08782495176671656,
                "initialization": "kaiming",
                "n_heads": 8,
                "n_layers": 2,
                "prenormalization": true,
                "residual_dropout": 0.0
            },
            "seed": 0,
            "training": {
                "batch_size": 1024,
                "eval_batch_size": 8192,
                "lr": 4.69162138270869e-05,
                "n_epochs": 1000000000,
                "optimizer": "adamw",
                "patience": 16,
                "weight_decay": 0.0009997786518737089
            }
        },
        "environment": {
            "devices": {
                "CUDA_VISIBLE_DEVICES": "0,1,2",
                "torch.version.cuda": "10.1",
                "torch.backends.cudnn.version()": 7603,
                "torch.cuda.nccl.version()": 2708,
                "driver": "450.80.02",
                "0": {
                    "name": "Tesla V100-PCIE-32GB",
                    "total_memory": 34089730048
                },
                "1": {
                    "name": "Tesla V100-PCIE-32GB",
                    "total_memory": 34089730048
                },
                "2": {
                    "name": "Tesla V100-PCIE-32GB",
                    "total_memory": 34089730048
                }
            }
        },
        "epoch_size": 707,
        "n_parameters": 203561,
        "best_epoch": 93,
        "metrics": {
            "train": {
                "rmse": 0.7137520011279275,
                "score": -0.7137520011279275
            },
            "val": {
                "rmse": 0.7420964762827985,
                "score": -0.7420964762827985
            },
            "test": {
                "rmse": 0.7464195589534499,
                "score": -0.7464195589534499
            }
        },
        "time": "0:53:39",
        "trial_id": 22,
        "tuning_time": "1 day, 7:54:27"
    },
    "time": "2 days, 3:04:42"
}
