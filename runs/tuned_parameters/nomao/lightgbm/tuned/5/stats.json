{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/nomao",
            "y_policy": "mean_std"
        },
        "fit": {
            "early_stopping_rounds": 50,
            "verbose": true
        },
        "model": {
            "colsample_bytree": 0.8049146089492032,
            "learning_rate": 0.0369702442162517,
            "min_child_samples": 78,
            "min_child_weight": 0.01342525377980585,
            "n_estimators": 2000,
            "n_jobs": 20,
            "num_leaves": 73,
            "reg_lambda": 0.0,
            "subsample": 0.5899126531544889
        },
        "seed": 5
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "1,0,3",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "455.32.00",
            "1": {
                "name": "Tesla V100-PCIE-16GB",
                "total_memory": 16945512448
            },
            "0": {
                "name": "Tesla V100-PCIE-16GB",
                "total_memory": 16945512448
            },
            "3": {
                "name": "Tesla V100-PCIE-16GB",
                "total_memory": 16945512448
            }
        }
    },
    "dataset": "nomao",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9940902021772939,
                "recall": 0.9962593516209476,
                "f1-score": 0.995173594893352,
                "support": 6416
            },
            "1": {
                "precision": 0.9985032740879326,
                "recall": 0.9976322512306063,
                "f1-score": 0.9980675726218675,
                "support": 16049
            },
            "accuracy": 0.9972401513465391,
            "macro avg": {
                "precision": 0.9962967381326133,
                "recall": 0.9969458014257769,
                "f1-score": 0.9966205837576098,
                "support": 22465
            },
            "weighted avg": {
                "precision": 0.9972429015360227,
                "recall": 0.9972401513465391,
                "f1-score": 0.99724105309789,
                "support": 22465
            },
            "roc_auc": 0.9999462272569558,
            "score": 0.9999462272569558
        },
        "val": {
            "0": {
                "precision": 0.9593160377358491,
                "recall": 0.9492415402567095,
                "f1-score": 0.9542521994134898,
                "support": 1714
            },
            "1": {
                "precision": 0.9797862453531598,
                "recall": 0.9839010732617826,
                "f1-score": 0.9818393480791617,
                "support": 4286
            },
            "accuracy": 0.974,
            "macro avg": {
                "precision": 0.9695511415445044,
                "recall": 0.9665713067592461,
                "f1-score": 0.9680457737463257,
                "support": 6000
            },
            "weighted avg": {
                "precision": 0.9739385893771481,
                "recall": 0.974,
                "f1-score": 0.9739586192770014,
                "support": 6000
            },
            "roc_auc": 0.9960395872480535,
            "score": 0.9960395872480535
        },
        "test": {
            "0": {
                "precision": 0.9528023598820059,
                "recall": 0.9422403733955659,
                "f1-score": 0.9474919331182166,
                "support": 1714
            },
            "1": {
                "precision": 0.9770034843205575,
                "recall": 0.9813345776948204,
                "f1-score": 0.9791642416482366,
                "support": 4286
            },
            "accuracy": 0.9701666666666666,
            "macro avg": {
                "precision": 0.9649029221012817,
                "recall": 0.9617874755451932,
                "f1-score": 0.9633280873832266,
                "support": 6000
            },
            "weighted avg": {
                "precision": 0.9700900297726113,
                "recall": 0.9701666666666666,
                "f1-score": 0.9701165188448275,
                "support": 6000
            },
            "roc_auc": 0.9957299034984599,
            "score": 0.9957299034984599
        }
    },
    "time": "0:00:16"
}
