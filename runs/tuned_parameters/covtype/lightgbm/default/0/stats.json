{
    "config": {
        "data": {
            "cat_policy": "indices",
            "path": "data/covtype"
        },
        "fit": {
            "early_stopping_rounds": 1999,
            "verbose": true
        },
        "model": {
            "n_estimators": 2000
        },
        "seed": 0
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "455.32.00",
            "0": {
                "name": "Tesla V100-PCIE-16GB",
                "total_memory": 16945512448
            }
        }
    },
    "dataset": "covtype",
    "algorithm": "lightgbm_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9353672008595512,
                "recall": 0.9117998495331101,
                "f1-score": 0.9234331814446851,
                "support": 135578
            },
            "1": {
                "precision": 0.9316630669546436,
                "recall": 0.9516413695728909,
                "f1-score": 0.9415462522373074,
                "support": 181312
            },
            "2": {
                "precision": 0.9803477275698288,
                "recall": 0.9832182501529586,
                "f1-score": 0.9817808906635247,
                "support": 22882
            },
            "3": {
                "precision": 0.9601366742596811,
                "recall": 0.9584991472427515,
                "f1-score": 0.9593172119487909,
                "support": 1759
            },
            "4": {
                "precision": 0.9353295535081503,
                "recall": 0.8689711934156379,
                "f1-score": 0.9009301134909122,
                "support": 6075
            },
            "5": {
                "precision": 0.9726986977997306,
                "recall": 0.9744489428699955,
                "f1-score": 0.9735730337078652,
                "support": 11115
            },
            "6": {
                "precision": 0.9778478578570879,
                "recall": 0.9685357306110011,
                "f1-score": 0.9731695181230147,
                "support": 13126
            },
            "accuracy": 0.9390179294172065,
            "macro avg": {
                "precision": 0.9561986826869532,
                "recall": 0.9453020690569065,
                "f1-score": 0.9505357430880144,
                "support": 371847
            },
            "weighted avg": {
                "precision": 0.939060983447306,
                "recall": 0.9390179294172065,
                "f1-score": 0.938912093090819,
                "support": 371847
            },
            "score": 0.9390179294172065
        },
        "val": {
            "0": {
                "precision": 0.9156084816817547,
                "recall": 0.8892429338525992,
                "f1-score": 0.9022331317727355,
                "support": 33894
            },
            "1": {
                "precision": 0.9120451072804355,
                "recall": 0.934962936816096,
                "f1-score": 0.9233618388801133,
                "support": 45328
            },
            "2": {
                "precision": 0.9236243707689638,
                "recall": 0.9300821534696732,
                "f1-score": 0.9268420135864832,
                "support": 5721
            },
            "3": {
                "precision": 0.6551020408163265,
                "recall": 0.7312072892938497,
                "f1-score": 0.6910656620021528,
                "support": 439
            },
            "4": {
                "precision": 0.8548872180451128,
                "recall": 0.7485187623436471,
                "f1-score": 0.7981747981747981,
                "support": 1519
            },
            "5": {
                "precision": 0.9036630036630037,
                "recall": 0.8877293990644116,
                "f1-score": 0.895625340352151,
                "support": 2779
            },
            "6": {
                "precision": 0.9304960195958358,
                "recall": 0.9259597806215722,
                "f1-score": 0.9282223579718998,
                "support": 3282
            },
            "accuracy": 0.9122544695682107,
            "macro avg": {
                "precision": 0.8707751774073476,
                "recall": 0.8639576079231215,
                "f1-score": 0.8665035918200477,
                "support": 92962
            },
            "weighted avg": {
                "precision": 0.9123104110251515,
                "recall": 0.9122544695682107,
                "f1-score": 0.912072376934016,
                "support": 92962
            },
            "score": 0.9122544695682107
        },
        "test": {
            "0": {
                "precision": 0.919056631241811,
                "recall": 0.8940237915407855,
                "f1-score": 0.9063673996793569,
                "support": 42368
            },
            "1": {
                "precision": 0.9143905843428513,
                "recall": 0.9364995323061718,
                "f1-score": 0.9253130122414814,
                "support": 56661
            },
            "2": {
                "precision": 0.9241226244971563,
                "recall": 0.931617955530695,
                "f1-score": 0.9278551532033426,
                "support": 7151
            },
            "3": {
                "precision": 0.6463815789473685,
                "recall": 0.7158469945355191,
                "f1-score": 0.6793431287813311,
                "support": 549
            },
            "4": {
                "precision": 0.8387878787878787,
                "recall": 0.7288046340179042,
                "f1-score": 0.7799380107072414,
                "support": 1899
            },
            "5": {
                "precision": 0.8897338403041825,
                "recall": 0.8758997984451483,
                "f1-score": 0.8827626233313987,
                "support": 3473
            },
            "6": {
                "precision": 0.9346758349705304,
                "recall": 0.9278400780107264,
                "f1-score": 0.931245412282848,
                "support": 4102
            },
            "accuracy": 0.9141588427149041,
            "macro avg": {
                "precision": 0.8667355675845397,
                "recall": 0.8586475406267073,
                "f1-score": 0.8618321057467142,
                "support": 116203
            },
            "weighted avg": {
                "precision": 0.9141681773342197,
                "recall": 0.9141588427149041,
                "f1-score": 0.9139617024417174,
                "support": 116203
            },
            "score": 0.9141588427149041
        }
    },
    "time": "0:15:33"
}
